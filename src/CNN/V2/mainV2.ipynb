{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2007f2",
   "metadata": {},
   "source": [
    "Alterações a serem feitas na V2:\n",
    "- Alterar as camadas.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aec0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imshow\n",
    "from sklearn.metrics import classification_report, confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.utils as np_utils\n",
    "from tensorflow.keras.utils import img_to_array , to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultData:\n",
    "    train_images:np.ndarray\n",
    "    test_images:np.ndarray\n",
    "    train_labels:np.ndarray\n",
    "    test_labels:np.ndarray\n",
    "    def __init__(self,t:tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]):\n",
    "        self.train_images = t[0]\n",
    "        self.test_images = t[1]\n",
    "        self.train_labels = t[2]\n",
    "        self.test_labels = t[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd70ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load20kPaths(\n",
    "        base_path:str = \"/kaggle/input/solarpanelpowerloss/data\",\n",
    "        num_images_per_class:int = 10000\n",
    "    ) -> list[str]:\n",
    "    zpaths:list[str] = list()\n",
    "    opaths:list[str] = list()\n",
    "    print(\"[INFO]: loading image paths...\")\n",
    "    \n",
    "    \n",
    "    dir_classes = os.listdir(base_path)\n",
    "    for d in dir_classes:\n",
    "        for file in os.listdir(os.path.join(base_path,d)):\n",
    "            if(int(d) == 0):\n",
    "                zpaths.append(os.path.join(d, file))\n",
    "            else:\n",
    "                opaths.append(os.path.join(d, file))\n",
    "    assert(len(zpaths) > 14500)\n",
    "    assert(len(opaths) > 30000)\n",
    "    print(\"[INFO]:Verifique os seguintes caminhos: \", zpaths[-2:],opaths[-2:])\n",
    "    random.seed(42)\n",
    "    random.shuffle(zpaths)\n",
    "    random.shuffle(opaths)\n",
    "    paths = zpaths[0:num_images_per_class] + opaths[0:num_images_per_class]\n",
    "    random.shuffle(paths)\n",
    "    assert(len(paths) == 2*num_images_per_class)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar metade das imagens e classes\n",
    "\n",
    "def LoadAndSplitDataset(\n",
    "        paths:list[str],base_path:str = \"/kaggle/input/solarpanelpowerloss/data\",\n",
    "        num_images_per_class:int = 10000) -> ResultData:\n",
    "    assert(len(paths) == int(num_images_per_class/2))\n",
    "    print(\"[INFO]: Loading the images...\")\n",
    "\n",
    "    classes:list[int] = list()\n",
    "    images:list[list[int,int,int]] = list()\n",
    "     \n",
    "    for path in tqdm(paths):\n",
    "        image = cv2.imread(os.path.join(base_path,path))\n",
    "        if (image is None):\n",
    "            print(f\"Image load failed with path: {path}\")\n",
    "            continue\n",
    "        classes.append(int(path.split(\"/\")[0]))\n",
    "        images.append( img_to_array( cv2.resize( image,(192, 192) ) ) )\n",
    "        \n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(images, dtype=\"float\") / 255.0\n",
    "    labels = np.array(classes, dtype=np.int32)\n",
    "\n",
    "    lenght = len(data)\n",
    "    assert(lenght == int(num_images_per_class/2) and lenght == len(labels))\n",
    "\n",
    "    (train_images, test_images, train_l, test_l) = train_test_split( data, labels, test_size=0.25, random_state=42)\n",
    "    print(\"[INFO]: Training image arrays = \", train_l)\n",
    "    print(\"[INFO]: Testing image arrays = \",test_l)\n",
    "    \n",
    "    # convert the labels from integers to vectors:\n",
    "    # Transforma labels -> [1,0...] em train_labels -> [[1.0,0.0],[0.0,1.0]...]\n",
    "    train_labels = np_utils.to_categorical(train_l, num_classes=2)\n",
    "    test_labels = np_utils.to_categorical(test_l, num_classes=2)\n",
    "    print(\"\\n[INFO]: Data.shape = \",data.shape)\n",
    "    return ResultData((train_images, test_images, train_labels, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f98442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowPics(train_images:np.ndarray, train_labels:np.ndarray):\n",
    "    print(\"[INFO]: Plotting images ...\")\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(20):\n",
    "        plt.subplot(5,4,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        img_float32 = np.float32(train_images[i])\n",
    "        plt.imshow(cv2.cvtColor(img_float32, cv2.COLOR_BGR2RGB) )\n",
    "        # labels\n",
    "        plt.xlabel( int(train_labels[i][1]) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1805dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão 1:\n",
    "# - Não utilizar ativação softmax.\n",
    "#Versão erro:\n",
    "# - CategoricalCrossentropy(from_logits=True)\n",
    "# Versão 2:\n",
    "# - Utilizar softmax, mas alterar tipo de loss.\n",
    "# Versão 3:\n",
    "# - Usar layers.BatchNormalization()\n",
    "# Versão 4:\n",
    "# - Reduzir o tamanho da imagem para 128 pixels.\n",
    "# Versão 5:\n",
    "# - Alterar test it para fazer a predição como (atual, não usar com softmax):\n",
    "#\n",
    "# Softmax\n",
    "#pred = self.instance.predict(test_images)\n",
    "#y_pred = np.argmax(pred, axis=1)\n",
    "#y_true = np.argmax(test_labels, axis=1)\n",
    "#\n",
    "# Logits + Sparse\n",
    "#y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "# Versão 6: dar variabilidade pro dataset?\n",
    "#data_augmentation = tf.keras.Sequential([\n",
    "#    layers.RandomFlip(\"horizontal\"),\n",
    "#    layers.RandomRotation(0.02),\n",
    "#    layers.RandomZoom(0.02),\n",
    "#])\n",
    "\n",
    "# Versão 7: evita overfitting\n",
    "# callback = tf.keras.callbacks.EarlyStopping(\n",
    "#    monitor='val_loss',\n",
    "#    patience=5,\n",
    "#    restore_best_weights=True\n",
    "#)\n",
    "\n",
    "# Versão 8: modelo melhor?\n",
    "#MobileNetV2\n",
    "class Model: \n",
    "    instance: Sequential \n",
    "    def __init__(self, s: Sequential): \n",
    "        self.instance = models.Sequential()\n",
    "\n",
    "    def configure(self, img_size:int = 192, kernel_size = 3, color_channel = 3) -> None:\n",
    "        self.instance.add(layers.Conv2D(img_size, kernel_size=(kernel_size, kernel_size), activation='relu', input_shape=(img_size, img_size, color_channel))) # 3 é sobre RGB\n",
    "        self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        self.instance.add(layers.Conv2D(128, kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
    "        self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.MaxPooling2D((2, 2)))\n",
    "       \n",
    "        self.instance.add(layers.Conv2D(64, kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
    "        self.instance.add(layers.Flatten())\n",
    "        self.instance.add(layers.Dropout(0.5))\n",
    "        \n",
    "        self.instance.add(layers.Dense(32, activation='relu')) # Dense: Núm. neurônios 1a cam\n",
    "        self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.Dense(8, activation='relu')) # Dense: Núm. neurônios 1a cam\n",
    "        \n",
    "        self.instance.add(layers.Dense(2))#activation=\"softmax\"))\n",
    "        self.instance.summary()\n",
    "    \n",
    "    def compile(self, optimizer:str = \"adam\") -> None:\n",
    "        self.instance.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def Run(self, rd: ResultData,epochs = 30, batch_size:int = 10):\n",
    "        history =  self.instance.fit( \n",
    "            rd.train_images, \n",
    "            rd.train_labels, \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(rd.test_images, rd.test_labels) \n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    \n",
    "    def Testit(self, rd: ResultData) -> float:\n",
    "        print(\"[INFO]: Generating test predictions...\")\n",
    "       \n",
    "        # make class predictions\n",
    "        #predictions = (self.instance.predict(test_images) > 0.5).astype(int)\n",
    "        predictions = self.instance.predict(rd.test_images)\n",
    "        # returns index of the maximum value in prediction array [0.0,0.0,1.0] -> 2\n",
    "        y_pred_class = np.argmax(predictions, axis=1)\n",
    "        y_test_class = np.argmax(rd.test_labels, axis=1)\n",
    "    \n",
    "        l = len(y_test_class)\n",
    "        acc = sum([y_pred_class[i]==y_test_class[i] for i in range(l)])/l\n",
    "        print('Accuracy: %.2f %%' % (acc*100))\n",
    "    \n",
    "        f1score = 0\n",
    "        f1score += f1_score(y_test_class,y_pred_class,average=\"weighted\")\n",
    "        print(\"F_measure: \",round(100*f1score, 2),\"%\")\n",
    "\n",
    "        print(\"Classes verdadeiras únicas:\", np.unique(y_test_class))\n",
    "        print(\"Classes preditas únicas:\", np.unique(y_pred_class))\n",
    "        #Confusion Matrix\n",
    "        cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "        return acc\n",
    "        \n",
    "    def Save(self,accuracy:float):\n",
    "        if (accuracy > 0.5):\n",
    "            self.instance.save(r'./kaggle/working/chewey.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47edf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTrainingAccuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    base_path = \"/kaggle/input/solarpanelpowerloss/data\"\n",
    "    num_images_per_class:int = 10000\n",
    "    assert(num_images_per_class < 14500)\n",
    "    assert(num_images_per_class % 4 == 0)\n",
    "\n",
    "    paths:list[str] = Load20kPaths(base_path,num_images_per_class)\n",
    "    \n",
    "    m: Model = Model(Sequential)\n",
    "    m.configure()\n",
    "    m.compile()\n",
    "    accuracy:float = 0.0\n",
    "    s\n",
    "    for i in range(0,4):\n",
    "        rd = LoadAndSplitDataset( \n",
    "                paths[int((i/2)*num_images_per_class):int( ((1+i)/2)*num_images_per_class)],\n",
    "                base_path,\n",
    "                num_images_per_class\n",
    "            ) \n",
    "        ShowPics(rd.train_images, rd.train_labels)\n",
    "        history = m.Run(rd, 10)\n",
    "        PlotTrainingAccuracy(history)\n",
    "        accuracy = m.Testit(rd)\n",
    "        \n",
    "    m.Save(accuracy)\n",
    "    \n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
