{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6678fdf6",
   "metadata": {},
   "source": [
    "28k imagens + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "    instance: Sequential \n",
    "    def __init__(self, s: Sequential): \n",
    "        self.instance = models.Sequential()\n",
    "\n",
    "    def configure(self, img_size:int = 192, kernel_size = 3, color_channel = 3) -> None:\n",
    "        \n",
    "        self.instance.add(layers.Conv2D(128, kernel_size=(kernel_size, kernel_size), activation='relu', input_shape=(img_size, img_size, color_channel))) # 3 é sobre RGB\n",
    "        #self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        self.instance.add(layers.Conv2D(64, kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
    "        #self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        self.instance.add(layers.Conv2D(32, kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
    "        #self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.Dropout(0.5))\n",
    "        \n",
    "        self.instance.add(layers.Flatten())\n",
    "        self.instance.add(layers.Dropout(0.5))\n",
    "        \n",
    "        self.instance.add(layers.Dense(16, activation='relu'))\n",
    "        #self.instance.add(layers.BatchNormalization())\n",
    "        self.instance.add(layers.Dropout(0.5))\n",
    "        \n",
    "        self.instance.add(layers.Dense(2))#activation=\"softmax\"))\n",
    "        self.instance.summary()\n",
    "    \n",
    "    def compile(self, optimizer:str = \"adam\") -> None:\n",
    "        self.instance.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def Run(self, rd: ResultData,epochs = 30, batch_size:int = 10):\n",
    "        #datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        #    rotation_range=10,\n",
    "        #    width_shift_range=0.05,\n",
    "        #    height_shift_range=0.05,\n",
    "        #    brightness_range=(0.8, 1.2),\n",
    "        #    horizontal_flip=True\n",
    "        #)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        history =  self.instance.fit( \n",
    "            rd.train_images, \n",
    "            rd.train_labels, \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(rd.test_images, rd.test_labels),\n",
    "            #callback=[callback]\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    \n",
    "    def Testit(self, rd: ResultData) -> float:\n",
    "        print(\"[INFO]: Generating test predictions...\")\n",
    "       \n",
    "        # make class predictions\n",
    "        #predictions = (self.instance.predict(test_images) > 0.5).astype(int)\n",
    "        predictions = self.instance.predict(rd.test_images)\n",
    "        # returns index of the maximum value in prediction array [0.0,0.0,1.0] -> 2\n",
    "        y_pred_class = np.argmax(predictions, axis=1)\n",
    "        y_test_class = np.argmax(rd.test_labels, axis=1)\n",
    "    \n",
    "        l = len(y_test_class)\n",
    "        acc = sum([y_pred_class[i]==y_test_class[i] for i in range(l)])/l\n",
    "        print('Accuracy: %.2f %%' % (acc*100))\n",
    "    \n",
    "        f1score = 0\n",
    "        f1score += f1_score(y_test_class,y_pred_class,average=\"weighted\")\n",
    "        print(\"F_measure: \",round(100*f1score, 2),\"%\")\n",
    "\n",
    "        print(\"Classes verdadeiras únicas:\", np.unique(y_test_class))\n",
    "        print(\"Classes preditas únicas:\", np.unique(y_pred_class))\n",
    "        #Confusion Matrix\n",
    "        cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "        return acc\n",
    "        \n",
    "    def Save(self,accuracy:float):\n",
    "        if (accuracy > 0.5):\n",
    "            self.instance.save(r'./kaggle/working/dice.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    base_path = \"/kaggle/input/solarpanelpowerloss/data\"\n",
    "    num_images_per_class:int = 14000\n",
    "    assert(num_images_per_class < 14500)\n",
    "    assert(num_images_per_class % 4 == 0)\n",
    "\n",
    "    paths:list[str] = Load20kPaths(base_path,num_images_per_class)\n",
    "    # 0   1\n",
    "    # 1   2\n",
    "    \n",
    "    m: Model = Model(Sequential)\n",
    "    m.configure()\n",
    "    m.compile()\n",
    "    accuracy:float = 0.0\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        rd = LoadAndSplitDataset( \n",
    "                paths[int((i/2)*num_images_per_class):int( ((1+i)/2)*num_images_per_class)],\n",
    "                base_path,\n",
    "                num_images_per_class\n",
    "            ) \n",
    "        ShowPics(rd.train_images, rd.train_labels)\n",
    "        history = m.Run(rd, 10)\n",
    "        PlotTrainingAccuracy(history)\n",
    "        accuracy = m.Testit(rd)\n",
    "        \n",
    "        \n",
    "    m.Save(accuracy)\n",
    "    \n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
